{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studi\n",
      "studi\n",
      "studi\n",
      "studi\n"
     ]
    }
   ],
   "source": [
    "# Steeming Example 1\n",
    "\n",
    "# Import steeming library\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "word_list = [\"Study\", \"Studying\", \"Studies\", \"Studied\"]\n",
    "\n",
    "for word in word_list:\n",
    "    print(porter.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studi\n",
      "leav\n",
      "decreas\n",
      "play\n"
     ]
    }
   ],
   "source": [
    "# Steeming Example 2\n",
    "\n",
    "# Import steeming library\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "word_list = [\"studies\", \"leaves\", \"decreases\", \"plays\"]\n",
    "\n",
    "for word in word_list:\n",
    "    print(porter.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studi\n",
      "studi\n",
      "studi\n",
      "studi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Steeming Example 3 - SNOWBALL - the same like Porter but support more lenguages\n",
    "\n",
    "# Import steeming library\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "\n",
    "word_list = [\"Study\", \"Studying\", \"Studies\", \"Studied\"]\n",
    "\n",
    "for word in word_list:\n",
    "    print(snowball.stem(word))\n",
    "    \n",
    "SnowballStemmer.languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Various Stemming Algorithms.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Various Stemming Algorithms.\"\n",
    "#Porter's Stemmer\n",
    "#Lovin's Stemmer\n",
    "#Dawson's Stemmer\n",
    "#Krovetz's Stemmer\n",
    "#Xerox Stemmer\n",
    "#Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmer: studi\n",
      "\n",
      "Lemmatizer: study\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Different between STEMMER and LEMMATIZER.\"\"\"\n",
    "\n",
    "#Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer =  PorterStemmer()\n",
    "print(f'Stemmer: {stemmer.stem(\"studies\")}')\n",
    "\n",
    "\n",
    "#Lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(f'\\nLemmatizer: {lemmatizer.lemmatize(\"studies\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoS as a verb ''v''.\n",
      "Study\n",
      "Studying\n",
      "Studies\n",
      "Studied\n",
      "study\n",
      "leave\n",
      "decrease\n",
      "play\n",
      "\n",
      "\n",
      "PoS as a noun ''n''.\n",
      "Study\n",
      "Studying\n",
      "Studies\n",
      "Studied\n",
      "study\n",
      "leaf\n",
      "decrease\n",
      "play\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Lemmatiezer implementation.PoS as a verb, noun\"\"\"\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "word_list = [\"Study\", \"Studying\", \"Studies\", \"Studied\", \"studies\", \"leaves\", \"decreases\", \"plays\"]\n",
    "\n",
    "print(\"PoS as a verb ''v''.\")\n",
    "for word_verb in word_list:\n",
    "    print(lemma.lemmatize(word_verb, pos='v'))\n",
    "    \n",
    "print(\"\\n\\nPoS as a noun ''n''.\")\n",
    "for word_noun in word_list:\n",
    "    print(lemma.lemmatize(word_noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list: [\"am\", \"is\", \"are\", \"was\", \"were\"] PoS as a verb v.\n",
      "be\n",
      "be\n",
      "be\n",
      "be\n",
      "be\n"
     ]
    }
   ],
   "source": [
    "'''Lemmatizer as for a list: [\"am\", \"is\", \"are\", \"was\", \"were\"].'''\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "word_list = [\"am\", \"is\", \"are\", \"was\", \"were\"]\n",
    "\n",
    "print('list: [\"am\", \"is\", \"are\", \"was\", \"were\"] PoS as a verb ''v''.')\n",
    "for word_verb in word_list:\n",
    "    print(lemma.lemmatize(word_verb, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study\n",
      "studying\n",
      "studying\n",
      "studying\n"
     ]
    }
   ],
   "source": [
    "'''Lemmatizer for different PoS values.'''\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "print(lemma.lemmatize('studying', pos='v'))\n",
    "print(lemma.lemmatize('studying', pos='n'))\n",
    "print(lemma.lemmatize('studying', pos='a'))\n",
    "print(lemma.lemmatize('studying', pos='r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Part of Speech (PoS) tagging.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Part of Speech (PoS) tagging.\"\"\"\n",
    "# CC - Coordinating Conjunction: And, But, For, Nor, Or, So, Yet...\n",
    "# CD - Cardinal Digit: One, Two, Three, Four, Five, Six...\n",
    "# DT - Determiner: The, A, An, This, That...., My. Your..., Any, A few, Most,..., One, Ten...Other, Another, Such, What...\n",
    "# EX -Existential There: There (There is a pen 'on' the desk.)\n",
    "# FW - Foreign Words: dolce, ersatz, esprit, quo, maitre\n",
    "# IN - Preposition/Subordinating Conjunction: At, In, One, Above, Behind\n",
    "# JJ - Adjective: New, Old, High, Special, Big, Local (They live in a 'beautiful' house.)\n",
    "# JJR - Adjective, Comparative: Newer, Bigger, HIgher (The new bird is 'angrier' that Robin.)\n",
    "# JJS - Adjective,  Superlative: Biggest, Darkest, Most\n",
    "# LS - List Marker: 1), 2), 3)\n",
    "# MD - Modal: Could, Will, Should\n",
    "# NN - Noun, Singular: Year, Home, Cost, Time, Education\n",
    "# NNS - Noun, Plural: Pens, Books, Hats\n",
    "# NNP - Proper Noun, Singular: April, Africa, Pratik\n",
    "# NNPS - Proper Noun, Plural: Americans, Indians\n",
    "# PDT - Predeterminer: All, Both, Half\n",
    "# POS - Possessive Endings: Parent's, Pratiks's\n",
    "# PRP - Persomal Pronoun: I, He, She\n",
    "# PRP$ - Possessive Proniun: My, His, Her, Hers, Yours\n",
    "# RB - Adverb: Really, Already, Still, Early, Now\n",
    "# RBR - Adverb, Comparative: Worse, Less, Better\n",
    "# RBS - Adverbm Superlative: Worst, Least, Best\n",
    "# RP - Particle - Aboard, About, Across, Along, At, Away\n",
    "# TO - To: To\n",
    "# UH - Interjection: Amen, Huh, Howdy, Dammit, Heck, Anyways\n",
    "# VB - Verb, Base Form: Take, Play, Sit, Listen\n",
    "# VBD - Verb, Pasr Tense: Took, Studied, Played\n",
    "# VBG - Verb, Present Pariciple: Playing, Studying\n",
    "# VBN - Verb, Past Participle: Taken, Languished, Dilapidated\n",
    "# VBP - Verb, Present Tense, Not Third Person Singular: Terminate, Appear, Cure\n",
    "# VBZ - Verb, Present Tense, Third Person Singular: Uses, Speaks, Slaps\n",
    "# WDT-  Wh-Determiner: That, What, Whatever, Which, Whichever\n",
    "# WP -  Wh-Pronoun: Who, Whom, Which, What\n",
    "# WP$ - Possessive Wh - Pronoun: Whose\n",
    "# WRB -  Wh - Adverb: How, HOwever, Why, Where, When"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Studying', 'VBG'), ('Study', 'NNP'), ('Studies', 'NNPS'), ('I', 'PRP')]\n"
     ]
    }
   ],
   "source": [
    "'''Implementation PoS tagging.'''\n",
    "import nltk\n",
    "\n",
    "tag = nltk.pos_tag(['Studying', 'Study', 'Studies', 'I'])\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DT'),\n",
       " ('very', 'RB'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('young', 'JJ'),\n",
       " ('lady', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('walking', 'VBG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('beach', 'NN')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentence = 'A very beautiful young lady is walking on the beach'\n",
    "\n",
    "tokenized_words = word_tokenize(sentence)\n",
    "\n",
    "for words in tokenized_words:\n",
    "    tagged_words = nltk.pos_tag(tokenized_words)\n",
    "    \n",
    "tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  A/DT\n",
      "  very/RB\n",
      "  (NP beautiful/JJ young/JJ lady/NN)\n",
      "  is/VBZ\n",
      "  walking/VBG\n",
      "  on/IN\n",
      "  (NP the/DT beach/NN))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Chunking implementation.\"\"\"\n",
    "\n",
    "#Extracing Noun Phrase from text\n",
    "\n",
    "# ? - optional character\n",
    "# * - 0 or more repetations\n",
    "\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>} \"\n",
    "\n",
    "# Creating a parser\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "\n",
    "# Parsing text\n",
    "output = parser.parse(tagged_words)\n",
    "print(output)\n",
    "\n",
    "# Visualize\n",
    "output.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP A/DT very/RB)\n",
      "  beautiful/JJ\n",
      "  young/JJ\n",
      "  (NP lady/NN is/VBZ walking/VBG on/IN the/DT beach/NN))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Chinking implementation.\"\"\"\n",
    "\n",
    "#Extracing Noun Phrase from text\n",
    "\n",
    "# * - 0 or more repetations\n",
    "# + - 1 or more repetations\n",
    "\n",
    "# Here we are taking the whole string and then exluding adjectives from that chunk.\n",
    "\n",
    "grammar = r\"\"\" NP: {<.*>+}\n",
    "               }<JJ>+{\"\"\"\n",
    "\n",
    "# Creating a parser\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "\n",
    "# Parsing text\n",
    "output = parser.parse(tagged_words)\n",
    "print(output)\n",
    "\n",
    "# Visualize\n",
    "output.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
